{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOqTvzmLXQX6Ijb/Y7qbLuG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"u3ovcKkp4XjY","executionInfo":{"status":"error","timestamp":1742364104318,"user_tz":-330,"elapsed":396932,"user":{"displayName":"luxshi karunakaran","userId":"14981122548573112690"}},"outputId":"360d6b4a-6358-4340-d064-c1b3b35923fa"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-2-8134a19051ba>:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  df['GENDER'] = df['GENDER'].replace({'M': 0, 'F': 1}).astype(int)\n","<ipython-input-2-8134a19051ba>:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  df['LUNG_CANCER'] = df['LUNG_CANCER'].replace({'YES': 1, 'NO': 0}).astype(int)\n","/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n","    scores = scorer(estimator, X_test, y_test, **score_params)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n","    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n","                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n","    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n","                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n","    raise ValueError(\n","ValueError: Classification metrics can't handle a mix of binary and continuous targets\n","\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n","    scores = scorer(estimator, X_test, y_test, **score_params)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n","    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n","                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n","    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n","                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n","    raise ValueError(\n","ValueError: Classification metrics can't handle a mix of binary and continuous targets\n","\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n","    scores = scorer(estimator, X_test, y_test, **score_params)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n","    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n","                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n","    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n","                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n","    raise ValueError(\n","ValueError: Classification metrics can't handle a mix of binary and continuous targets\n","\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n","    scores = scorer(estimator, X_test, y_test, **score_params)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n","    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n","                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n","    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n","                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n","    raise ValueError(\n","ValueError: Classification metrics can't handle a mix of binary and continuous targets\n","\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n","    scores = scorer(estimator, X_test, y_test, **score_params)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n","    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n","                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n","    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n","                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n","    raise ValueError(\n","ValueError: Classification metrics can't handle a mix of binary and continuous targets\n","\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n","    scores = scorer(estimator, X_test, y_test, **score_params)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n","    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n","                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n","    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n","                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n","    raise ValueError(\n","ValueError: Classification metrics can't handle a mix of binary and continuous targets\n","\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n","    scores = scorer(estimator, X_test, y_test, **score_params)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n","    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n","                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n","    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n","                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n","    raise ValueError(\n","ValueError: Classification metrics can't handle a mix of binary and continuous targets\n","\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n","    scores = scorer(estimator, X_test, y_test, **score_params)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n","    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n","                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n","    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n","                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n","    raise ValueError(\n","ValueError: Classification metrics can't handle a mix of binary and continuous targets\n","\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n","    scores = scorer(estimator, X_test, y_test, **score_params)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n","    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n","                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n","    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n","                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n","    raise ValueError(\n","ValueError: Classification metrics can't handle a mix of binary and continuous targets\n","\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 949, in _score\n","    scores = scorer(estimator, X_test, y_test, **score_params)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 288, in __call__\n","    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n","                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n","    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n","                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n","    raise ValueError(\n","ValueError: Classification metrics can't handle a mix of binary and continuous targets\n","\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan]\n","  warnings.warn(\n"]},{"output_type":"error","ename":"ValueError","evalue":"Classification metrics can't handle a mix of binary and continuous targets","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-8134a19051ba>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitivity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecificity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         results.append({\n\u001b[1;32m    102\u001b[0m             \u001b[0;34m'Model'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-8134a19051ba>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0msensitivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    108\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m    109\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"]}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, roc_curve, auc\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression, LinearRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from xgboost import XGBClassifier\n","from sklearn.preprocessing import StandardScaler\n","\n","# Load the dataset\n","df = pd.read_csv(\"/content/lung cancer.csv\")\n","\n","# Data preprocessing\n","df['GENDER'] = df['GENDER'].replace({'M': 0, 'F': 1}).astype(int)\n","df['LUNG_CANCER'] = df['LUNG_CANCER'].replace({'YES': 1, 'NO': 0}).astype(int)\n","\n","# Features and target variable\n","x = df.drop('LUNG_CANCER', axis=1)\n","y = df['LUNG_CANCER']\n","\n","# Standardize the features\n","scaler = StandardScaler()\n","x = scaler.fit_transform(x)\n","\n","# Holdout method\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=32)\n","\n","# Function to evaluate models\n","def evaluate_model(model, x_train, y_train, x_test, y_test):\n","    model.fit(x_train, y_train)\n","    y_pred = model.predict(x_test)\n","\n","    acc = accuracy_score(y_test, y_pred)\n","    sensitivity = recall_score(y_test, y_pred)\n","    cm = confusion_matrix(y_test, y_pred)\n","    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1]) if (cm[0, 0] + cm[0, 1]) > 0 else 0\n","\n","    return acc, sensitivity, specificity, y_pred\n","\n","# Initialize models\n","models = {\n","    'GaussianNB': GaussianNB(),\n","    'SVC': SVC(probability=True),\n","    'Logistic Regression': LogisticRegression(max_iter=200),\n","    'Decision Tree': DecisionTreeClassifier(),\n","    'Random Forest': RandomForestClassifier(),\n","    'Gradient Boosting': GradientBoostingClassifier(),\n","    'XGBoost': XGBClassifier(),\n","    'Linear Regression': LinearRegression()\n","}\n","\n","# Hyperparameter tuning for all models\n","param_grids = {\n","    'GaussianNB': {},\n","    'SVC': {\n","        'C': [0.01, 0.1, 1, 10, 100],\n","        'kernel': ['linear', 'rbf', 'poly']\n","    },\n","    'Logistic Regression': {\n","        'C': [0.01, 0.1, 1, 10, 100],\n","        'solver': ['lbfgs', 'liblinear']\n","    },\n","    'Decision Tree': {\n","        'max_depth': [None, 10, 20, 30],\n","        'min_samples_split': [2, 5, 10]\n","    },\n","    'Random Forest': {\n","        'n_estimators': [50, 100, 200],\n","        'max_depth': [None, 10, 20, 30],\n","        'min_samples_split': [2, 5, 10]\n","    },\n","    'Gradient Boosting': {\n","        'n_estimators': [50, 100],\n","        'learning_rate': [0.01, 0.1, 0.2],\n","        'max_depth': [3, 5, 7]\n","    },\n","    'XGBoost': {\n","        'n_estimators': [50, 100],\n","        'learning_rate': [0.01, 0.1, 0.2],\n","        'max_depth': [3, 5, 7]\n","    },\n","    'Linear Regression': {\n","        'fit_intercept': [True, False]\n","    }\n","}\n","\n","# Store results\n","results = []\n","\n","# Evaluate each model using the holdout method\n","for name, model in models.items():\n","    if name in param_grids and param_grids[name]:  # Check if there are hyperparameters to tune\n","        grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='accuracy')\n","        grid_search.fit(x_train, y_train)\n","        best_model = grid_search.best_estimator_\n","        acc, sensitivity, specificity, y_pred = evaluate_model(best_model, x_train, y_train, x_test, y_test)\n","        results.append({\n","            'Model': name,\n","            'Best Params': grid_search.best_params_,\n","            'Holdout Accuracy': acc,\n","            'Holdout Sensitivity': sensitivity,\n","            'Holdout Specificity': specificity\n","        })\n","    else:\n","        acc, sensitivity, specificity, y_pred = evaluate_model(model, x_train, y_train, x_test, y_test)\n","        results.append({\n","            'Model': name,\n","            'Holdout Accuracy': acc,\n","            'Holdout Sensitivity': sensitivity,\n","            'Holdout Specificity': specificity\n","        })\n","\n","# Create a DataFrame for results\n","results_df = pd.DataFrame(results)\n","\n","# Display results\n","print(results_df)\n","\n","# Plotting Accuracy, Sensitivity, and Specificity for Holdout Method\n","holdout_results = results_df[results_df['Holdout Accuracy'].notnull()]\n","holdout_results.set_index('Model')[['Holdout Accuracy', 'Holdout Sensitivity', 'Holdout Specificity']].plot(kind='bar', figsize=(12, 6))\n","plt.title('Model Performance Metrics (Holdout Method)')\n","plt.ylabel('Scores')\n","plt.ylim(0, 1)\n","plt.xticks(rotation=45)\n","plt.show()\n","\n","# ROC Curve for Holdout Method\n","plt.figure(figsize=(12, 6))\n","for name, model in models.items():\n","    if name in param_grids and param_grids[name]:  # Check if there are hyperparameters to tune\n","        model.fit(x_train, y_train)\n","        y_pred_proba = model.predict_proba(x_test)[:, 1]\n","    else:\n","        model.fit(x_train, y_train)\n","        if name == 'Linear Regression':\n","            y_pred_proba = model.predict(x_test)\n","            y_pred_proba = np.where(y_pred_proba > 0.5, 1, 0)  # Convert to binary predictions\n","        else:\n","            y_pred_proba = model.predict_proba(x_test)[:, 1]\n","\n","    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n","    roc_auc = auc(fpr, tpr)\n","    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n","\n","plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC) Curve (Holdout Method)')\n","plt.legend(loc='lower right')\n","plt.show()"]}]}